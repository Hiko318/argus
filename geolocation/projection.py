"""\nPinhole Projection Module for Foresight SAR System\n\nThis module implements pinhole camera projection for converting between\nimage coordinates and 3D rays, supporting geolocation calculations\nwith camera pose and coordinate transformations.\n"""\n\nimport numpy as np\nfrom typing import Tuple, Optional, Union, List\nfrom dataclasses import dataclass\nimport logging\nfrom enum import Enum\n\nfrom .camera_calibration import CalibrationData, CameraCalibrator\n\n\nclass CoordinateSystem(Enum):\n    \"\"\"Coordinate system types\"\"\"\n    CAMERA = \"camera\"  # Camera coordinate system\n    WORLD = \"world\"    # World coordinate system\n    ENU = \"enu\"        # East-North-Up\n    NED = \"ned\"        # North-East-Down\n    ECEF = \"ecef\"      # Earth-Centered Earth-Fixed\n\n\n@dataclass\nclass CameraPose:\n    \"\"\"Camera pose in world coordinates\"\"\"\n    # Position (translation)\n    position: np.ndarray  # [x, y, z] in world coordinates\n    \n    # Orientation (rotation)\n    rotation_matrix: Optional[np.ndarray] = None  # 3x3 rotation matrix\n    quaternion: Optional[np.ndarray] = None       # [w, x, y, z] quaternion\n    euler_angles: Optional[np.ndarray] = None     # [roll, pitch, yaw] in radians\n    \n    # Coordinate system\n    coordinate_system: CoordinateSystem = CoordinateSystem.WORLD\n    \n    def __post_init__(self):\n        \"\"\"Validate and convert pose representations\"\"\"\n        if self.position.shape != (3,):\n            raise ValueError(f\"Position must be 3D vector, got shape {self.position.shape}\")\n        \n        # Ensure we have a rotation matrix\n        if self.rotation_matrix is None:\n            if self.quaternion is not None:\n                self.rotation_matrix = self._quaternion_to_rotation_matrix(self.quaternion)\n            elif self.euler_angles is not None:\n                self.rotation_matrix = self._euler_to_rotation_matrix(self.euler_angles)\n            else:\n                # Default to identity (no rotation)\n                self.rotation_matrix = np.eye(3)\n        \n        # Validate rotation matrix\n        if not self._is_valid_rotation_matrix(self.rotation_matrix):\n            logging.warning(\"Invalid rotation matrix detected, normalizing\")\n            self.rotation_matrix = self._normalize_rotation_matrix(self.rotation_matrix)\n    \n    @staticmethod\n    def _quaternion_to_rotation_matrix(q: np.ndarray) -> np.ndarray:\n        \"\"\"Convert quaternion to rotation matrix\"\"\"\n        w, x, y, z = q / np.linalg.norm(q)  # Normalize\n        \n        return np.array([\n            [1 - 2*(y*y + z*z), 2*(x*y - w*z), 2*(x*z + w*y)],\n            [2*(x*y + w*z), 1 - 2*(x*x + z*z), 2*(y*z - w*x)],\n            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x*x + y*y)]\n        ])\n    \n    @staticmethod\n    def _euler_to_rotation_matrix(angles: np.ndarray) -> np.ndarray:\n        \"\"\"Convert Euler angles (roll, pitch, yaw) to rotation matrix\"\"\"\n        roll, pitch, yaw = angles\n        \n        # Rotation matrices for each axis\n        R_x = np.array([\n            [1, 0, 0],\n            [0, np.cos(roll), -np.sin(roll)],\n            [0, np.sin(roll), np.cos(roll)]\n        ])\n        \n        R_y = np.array([\n            [np.cos(pitch), 0, np.sin(pitch)],\n            [0, 1, 0],\n            [-np.sin(pitch), 0, np.cos(pitch)]\n        ])\n        \n        R_z = np.array([\n            [np.cos(yaw), -np.sin(yaw), 0],\n            [np.sin(yaw), np.cos(yaw), 0],\n            [0, 0, 1]\n        ])\n        \n        # Combined rotation (ZYX order)\n        return R_z @ R_y @ R_x\n    \n    @staticmethod\n    def _is_valid_rotation_matrix(R: np.ndarray) -> bool:\n        \"\"\"Check if matrix is a valid rotation matrix\"\"\"\n        if R.shape != (3, 3):\n            return False\n        \n        # Check orthogonality: R @ R.T should be identity\n        should_be_identity = R @ R.T\n        identity = np.eye(3)\n        \n        # Check determinant should be 1\n        det = np.linalg.det(R)\n        \n        return (np.allclose(should_be_identity, identity, atol=1e-6) and \n                np.allclose(det, 1.0, atol=1e-6))\n    \n    @staticmethod\n    def _normalize_rotation_matrix(R: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize rotation matrix using SVD\"\"\"\n        U, _, Vt = np.linalg.svd(R)\n        R_normalized = U @ Vt\n        \n        # Ensure proper rotation (det = 1)\n        if np.linalg.det(R_normalized) < 0:\n            Vt[-1, :] *= -1\n            R_normalized = U @ Vt\n        \n        return R_normalized\n    \n    def get_transformation_matrix(self) -> np.ndarray:\n        \"\"\"Get 4x4 transformation matrix [R|t]\"\"\"\n        T = np.eye(4)\n        T[:3, :3] = self.rotation_matrix\n        T[:3, 3] = self.position\n        return T\n    \n    def inverse(self) -> 'CameraPose':\n        \"\"\"Get inverse camera pose\"\"\"\n        R_inv = self.rotation_matrix.T\n        t_inv = -R_inv @ self.position\n        \n        return CameraPose(\n            position=t_inv,\n            rotation_matrix=R_inv,\n            coordinate_system=self.coordinate_system\n        )\n\n\n@dataclass\nclass Ray3D:\n    \"\"\"3D ray representation\"\"\"\n    origin: np.ndarray      # Ray origin point\n    direction: np.ndarray   # Ray direction (normalized)\n    \n    def __post_init__(self):\n        \"\"\"Normalize direction vector\"\"\"\n        self.direction = self.direction / np.linalg.norm(self.direction)\n    \n    def point_at_distance(self, distance: float) -> np.ndarray:\n        \"\"\"Get point along ray at given distance\"\"\"\n        return self.origin + distance * self.direction\n    \n    def intersect_plane(self, plane_point: np.ndarray, plane_normal: np.ndarray) -> Optional[np.ndarray]:\n        \"\"\"Intersect ray with plane\"\"\"\n        plane_normal = plane_normal / np.linalg.norm(plane_normal)\n        \n        # Check if ray is parallel to plane\n        denom = np.dot(self.direction, plane_normal)\n        if abs(denom) < 1e-6:\n            return None\n        \n        # Calculate intersection distance\n        t = np.dot(plane_point - self.origin, plane_normal) / denom\n        \n        if t < 0:\n            return None  # Intersection behind ray origin\n        \n        return self.point_at_distance(t)\n    \n    def intersect_ground_plane(self, ground_height: float = 0.0) -> Optional[np.ndarray]:\n        \"\"\"Intersect ray with horizontal ground plane\"\"\"\n        # Ground plane normal points up (Z-axis)\n        plane_normal = np.array([0, 0, 1])\n        plane_point = np.array([0, 0, ground_height])\n        \n        return self.intersect_plane(plane_point, plane_normal)\n\n\nclass PinholeProjector:\n    \"\"\"Pinhole camera projection model\"\"\"\n    \n    def __init__(self, calibration_data: CalibrationData):\n        \"\"\"\n        Initialize pinhole projector\n        \n        Args:\n            calibration_data: Camera calibration parameters\n        \"\"\"\n        self.calibration = calibration_data\n        self.camera_matrix = calibration_data.camera_matrix\n        self.distortion_coeffs = calibration_data.distortion_coeffs\n        \n        # Extract camera parameters\n        self.fx = self.camera_matrix[0, 0]\n        self.fy = self.camera_matrix[1, 1]\n        self.cx = self.camera_matrix[0, 2]\n        self.cy = self.camera_matrix[1, 2]\n        \n        # Camera matrix inverse for back-projection\n        self.camera_matrix_inv = np.linalg.inv(self.camera_matrix)\n    \n    def pixel_to_ray(self, pixel_coords: Union[np.ndarray, Tuple[float, float]], \n                     camera_pose: Optional[CameraPose] = None) -> Ray3D:\n        \"\"\"\n        Convert pixel coordinates to 3D ray\n        \n        Args:\n            pixel_coords: Pixel coordinates [u, v]\n            camera_pose: Camera pose in world coordinates\n            \n        Returns:\n            3D ray in world coordinates\n        \"\"\"\n        if isinstance(pixel_coords, tuple):\n            pixel_coords = np.array(pixel_coords)\n        \n        # Undistort pixel coordinates\n        undistorted = self.calibration.undistort_points(pixel_coords.reshape(1, 2))\n        u_undist, v_undist = undistorted[0]\n        \n        # Convert to normalized camera coordinates\n        x_norm = (u_undist - self.cx) / self.fx\n        y_norm = (v_undist - self.cy) / self.fy\n        \n        # Ray direction in camera coordinates (pointing forward)\n        ray_direction_camera = np.array([x_norm, y_norm, 1.0])\n        ray_direction_camera = ray_direction_camera / np.linalg.norm(ray_direction_camera)\n        \n        # Ray origin at camera center\n        ray_origin_camera = np.array([0.0, 0.0, 0.0])\n        \n        if camera_pose is None:\n            # Return ray in camera coordinates\n            return Ray3D(origin=ray_origin_camera, direction=ray_direction_camera)\n        \n        # Transform to world coordinates\n        ray_origin_world = camera_pose.rotation_matrix @ ray_origin_camera + camera_pose.position\n        ray_direction_world = camera_pose.rotation_matrix @ ray_direction_camera\n        \n        return Ray3D(origin=ray_origin_world, direction=ray_direction_world)\n    \n    def ray_to_pixel(self, ray: Ray3D, camera_pose: Optional[CameraPose] = None) -> Optional[np.ndarray]:\n        \"\"\"\n        Convert 3D ray to pixel coordinates\n        \n        Args:\n            ray: 3D ray\n            camera_pose: Camera pose in world coordinates\n            \n        Returns:\n            Pixel coordinates [u, v] or None if behind camera\n        \"\"\"\n        if camera_pose is not None:\n            # Transform ray to camera coordinates\n            camera_pose_inv = camera_pose.inverse()\n            ray_origin_camera = camera_pose_inv.rotation_matrix @ (ray.origin - camera_pose_inv.position)\n            ray_direction_camera = camera_pose_inv.rotation_matrix @ ray.direction\n        else:\n            ray_origin_camera = ray.origin\n            ray_direction_camera = ray.direction\n        \n        # Check if ray points forward (positive Z)\n        if ray_direction_camera[2] <= 0:\n            return None\n        \n        # Project to image plane (Z = 1)\n        scale = 1.0 / ray_direction_camera[2]\n        x_norm = ray_direction_camera[0] * scale\n        y_norm = ray_direction_camera[1] * scale\n        \n        # Convert to pixel coordinates\n        u = self.fx * x_norm + self.cx\n        v = self.fy * y_norm + self.cy\n        \n        # Apply distortion\n        pixel_coords = np.array([[u, v]], dtype=np.float32)\n        \n        # Note: OpenCV undistortPoints is used for undistortion,\n        # for distortion we would need the inverse operation\n        # For now, return undistorted coordinates\n        \n        return np.array([u, v])\n    \n    def project_point(self, point_3d: np.ndarray, camera_pose: Optional[CameraPose] = None) -> Optional[np.ndarray]:\n        \"\"\"\n        Project 3D point to pixel coordinates\n        \n        Args:\n            point_3d: 3D point in world coordinates\n            camera_pose: Camera pose in world coordinates\n            \n        Returns:\n            Pixel coordinates [u, v] or None if behind camera\n        \"\"\"\n        if camera_pose is not None:\n            # Transform point to camera coordinates\n            camera_pose_inv = camera_pose.inverse()\n            point_camera = camera_pose_inv.rotation_matrix @ (point_3d - camera_pose_inv.position)\n        else:\n            point_camera = point_3d\n        \n        # Check if point is in front of camera\n        if point_camera[2] <= 0:\n            return None\n        \n        # Project using camera matrix\n        point_homogeneous = np.array([point_camera[0], point_camera[1], point_camera[2], 1.0])\n        \n        # Apply camera matrix\n        pixel_homogeneous = self.camera_matrix @ point_camera\n        \n        # Convert to pixel coordinates\n        u = pixel_homogeneous[0] / pixel_homogeneous[2]\n        v = pixel_homogeneous[1] / pixel_homogeneous[2]\n        \n        return np.array([u, v])\n    \n    def backproject_to_depth(self, pixel_coords: Union[np.ndarray, Tuple[float, float]], \n                           depth: float, camera_pose: Optional[CameraPose] = None) -> np.ndarray:\n        \"\"\"\n        Backproject pixel to 3D point at given depth\n        \n        Args:\n            pixel_coords: Pixel coordinates [u, v]\n            depth: Depth along camera Z-axis\n            camera_pose: Camera pose in world coordinates\n            \n        Returns:\n            3D point in world coordinates\n        \"\"\"\n        # Get ray from pixel\n        ray = self.pixel_to_ray(pixel_coords, camera_pose=None)\n        \n        # Point at given depth in camera coordinates\n        point_camera = ray.origin + depth * ray.direction\n        \n        if camera_pose is None:\n            return point_camera\n        \n        # Transform to world coordinates\n        point_world = camera_pose.rotation_matrix @ point_camera + camera_pose.position\n        return point_world\n    \n    def get_field_of_view(self) -> Tuple[float, float]:\n        \"\"\"Get horizontal and vertical field of view in degrees\"\"\"\n        return self.calibration.get_field_of_view()\n    \n    def is_pixel_in_image(self, pixel_coords: np.ndarray, margin: int = 0) -> bool:\n        \"\"\"Check if pixel coordinates are within image bounds\"\"\"\n        u, v = pixel_coords\n        return (margin <= u < self.calibration.image_width - margin and\n                margin <= v < self.calibration.image_height - margin)\n    \n    def get_image_corners_rays(self, camera_pose: Optional[CameraPose] = None) -> List[Ray3D]:\n        \"\"\"Get rays for image corner pixels\"\"\"\n        corners = [\n            [0, 0],  # Top-left\n            [self.calibration.image_width - 1, 0],  # Top-right\n            [self.calibration.image_width - 1, self.calibration.image_height - 1],  # Bottom-right\n            [0, self.calibration.image_height - 1]  # Bottom-left\n        ]\n        \n        return [self.pixel_to_ray(corner, camera_pose) for corner in corners]\n    \n    def estimate_ground_coverage(self, camera_pose: CameraPose, \n                               ground_height: float = 0.0) -> Optional[np.ndarray]:\n        \"\"\"\n        Estimate ground coverage area\n        \n        Args:\n            camera_pose: Camera pose in world coordinates\n            ground_height: Ground plane height\n            \n        Returns:\n            Array of ground intersection points for image corners\n        \"\"\"\n        corner_rays = self.get_image_corners_rays(camera_pose)\n        ground_points = []\n        \n        for ray in corner_rays:\n            intersection = ray.intersect_ground_plane(ground_height)\n            if intersection is not None:\n                ground_points.append(intersection)\n        \n        if len(ground_points) < 3:\n            return None  # Not enough intersections\n        \n        return np.array(ground_points)\n    \n    def get_projection_info(self) -> dict:\n        \"\"\"Get projection information summary\"\"\"\n        fov_h, fov_v = self.get_field_of_view()\n        \n        return {\n            'camera_model': 'pinhole',\n            'image_size': f\"{self.calibration.image_width}x{self.calibration.image_height}\",\n            'focal_lengths': f\"fx={self.fx:.2f}, fy={self.fy:.2f}\",\n            'principal_point': f\"cx={self.cx:.2f}, cy={self.cy:.2f}\",\n            'field_of_view': f\"horizontal={fov_h:.1f}°, vertical={fov_v:.1f}°\",\n            'distortion_model': self.calibration.distortion_model.value\n        }\n"},"query_language":"English"}}