# Jetson-Optimized Requirements for Foresight SAR System
# Install this on NVIDIA Jetson devices (Orin, Xavier, Nano)
# Prerequisites: JetPack 5.1+ with CUDA, cuDNN, TensorRT pre-installed

# Core AI/ML Dependencies (Jetson-optimized versions)
# Note: Install PyTorch from NVIDIA's wheel for Jetson
torch==2.1.0+nv23.05  # Install via: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
torchvision==0.16.0+nv23.05

# Computer Vision (use Jetson-optimized OpenCV)
opencv-python==4.9.0.80  # Or use pre-built OpenCV with CUDA support
ultralytics==8.0.232
numpy==1.24.4
scipy==1.11.4
pillow==10.2.0

# Face Recognition and Person Re-ID
facenet-pytorch==2.5.3
torchmetrics==1.2.1
insightface==0.7.3
scikit-learn==1.3.2

# Web Framework
fastapi==0.108.0
uvicorn[standard]==0.25.0
websockets==12.0

# Drone Integration
djitellopy==2.5.0
av==11.0.0

# Mapping and Geospatial
folium==0.15.1
geopy==2.4.1
geographiclib==2.0

# Utilities
requests==2.31.0
pydantic==2.5.3
python-multipart==0.0.6

# Jetson-Specific Packages
jetson-stats==4.2.7  # System monitoring for Jetson devices
pycuda==2023.1      # CUDA Python bindings

# TensorRT Python API (usually pre-installed with JetPack)
# tensorrt==8.6.1  # Uncomment if not available via JetPack

# Performance Optimization
psutil==5.9.6        # System resource monitoring
GPUtil==1.4.0        # GPU utilization monitoring

# Optional: Additional computer vision libraries
scikit-image==0.22.0  # Advanced image processing
matplotlib==3.8.2     # Plotting and visualization

# Development Tools (optional for production)
pytest==8.4.2
pytest-asyncio==1.2.0
black==25.1.0
flake8==7.3.0

# Installation Notes:
# 1. Install JetPack 5.1+ first (includes CUDA, cuDNN, TensorRT)
# 2. Install PyTorch for Jetson:
#    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
# 3. For OpenCV with CUDA support, consider building from source or using:
#    sudo apt-get install python3-opencv
# 4. Install this requirements file:
#    pip install -r requirements-jetson.txt
# 5. Verify GPU acceleration:
#    python -c "import torch; print(torch.cuda.is_available())"
#    python -c "import cv2; print(cv2.cuda.getCudaEnabledDeviceCount())"

# Memory Management Tips:
# - Use torch.cuda.empty_cache() periodically
# - Set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
# - Monitor memory with jetson-stats: sudo jtop

# Performance Tuning:
# - Enable max performance mode: sudo nvpmodel -m 0
# - Set max CPU frequency: sudo jetson_clocks
# - Use TensorRT for inference optimization
# - Consider model quantization (FP16/INT8) for better performance