from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import asyncio, json, time, cv2
from ultralytics import YOLO
from typing import List
from contextlib import asynccontextmanager

# === LIFESPAN FIX ===
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup code here (if any)
    print("Starting Foresight backend...")
    yield
    # Shutdown code here (if any)
    print("Shutting down Foresight backend...")

app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

clients: List[WebSocket] = []

@app.get("/")
def root():
    return {"message": "Foresight backend is running!"}

@app.websocket("/ws")
async def ws_endpoint(ws: WebSocket):
    await ws.accept()
    clients.append(ws)
    try:
        while True:
            await asyncio.sleep(0.1)
    except Exception:
        pass
    finally:
        clients.remove(ws)

async def broadcast(obj):
    dead = []
    for c in clients:
        try:
            await c.send_text(json.dumps(obj))
        except Exception:
            dead.append(c)
    for d in dead:
        if d in clients:
            clients.remove(d)

# === VIDEO/YOLO CONFIG ===
VIDEO_SOURCE = "rtsp://127.0.0.1:8554/live.sdp"   # from scrcpy+ffmpeg
MODEL_PATH = "yolov8n.pt"
model = YOLO(MODEL_PATH)

def gen_frames():
    cap = cv2.VideoCapture(VIDEO_SOURCE)
    if not cap.isOpened():
        print("⚠️ Warning: Cannot open video source. Is scrcpy/ffmpeg running?")
        while True:
            black = 255 * (cv2.imread("blank.jpg") if cv2.imread("blank.jpg") is not None else cv2.UMat(480, 640, cv2.CV_8UC3))
            ret2, jpeg = cv2.imencode('.jpg', black)
            frame_bytes = jpeg.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            time.sleep(0.1)

    while True:
        ret, frame = cap.read()
        if not ret:
            continue

        results = model(frame)
        annotated = results[0].plot()

        # Broadcast detections
        dets = []
        for box in results[0].boxes.data.tolist():
            x1, y1, x2, y2, conf, cls = box
            dets.append({
                "cls": model.names[int(cls)],
                "conf": float(conf),
                "bbox": [float(x1), float(y1), float(x2), float(y2)]
            })
        payload = {"type": "detections", "time": time.time(), "detections": dets}
        asyncio.create_task(broadcast(payload))

        # Encode frame to JPEG
        ret2, jpeg = cv2.imencode('.jpg', annotated)
        if not ret2:
            continue
        frame_bytes = jpeg.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.get("/video_feed")
def video_feed():
    return StreamingResponse(gen_frames(),
        media_type='multipart/x-mixed-replace; boundary=frame')
